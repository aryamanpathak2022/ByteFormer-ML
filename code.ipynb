{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "535enlBoMgO3"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Layer, Dense, Flatten, Dropout, LayerNormalization\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j0Fa289OQluL"
      },
      "outputs": [],
      "source": [
        "class PatchEmbedding(Layer):\n",
        "    def __init__(self, patch_size, embed_dim):\n",
        "        super(PatchEmbedding, self).__init__()\n",
        "        self.patch_size = patch_size\n",
        "        self.embed_dim = embed_dim\n",
        "        self.projection = Dense(embed_dim)\n",
        "\n",
        "    def call(self, images):\n",
        "        batch_size = tf.shape(images)[0]\n",
        "        patches = tf.image.extract_patches(\n",
        "            images=images,\n",
        "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
        "            strides=[1, self.patch_size, self.patch_size, 1],\n",
        "            rates=[1, 1, 1, 1],\n",
        "            padding='VALID'\n",
        "        )\n",
        "        patch_dims = patches.shape[-1]\n",
        "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
        "        embeddings = self.projection(patches)\n",
        "        return embeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UqtyAgtmQpIQ"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(Layer):\n",
        "    def __init__(self, num_patches, embed_dim):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.pos_encoding = self.positional_encoding(num_patches, embed_dim)\n",
        "\n",
        "    def positional_encoding(self, num_patches, embed_dim):\n",
        "        # Create a range for positions and the division term\n",
        "        positions = tf.range(num_patches, dtype=tf.float32)[:, tf.newaxis]  # Shape: [num_patches, 1]\n",
        "        div_term = tf.exp(tf.range(0, embed_dim, 2, dtype=tf.float32) * -(tf.math.log(10000.0) / embed_dim))\n",
        "\n",
        "        # Compute sine and cosine for even and odd indices\n",
        "        even_indices = tf.sin(positions * div_term)\n",
        "        odd_indices = tf.cos(positions * div_term)\n",
        "\n",
        "        # Combine even and odd indices\n",
        "        pos_encoding = tf.concat([even_indices, odd_indices], axis=1)\n",
        "\n",
        "        return pos_encoding[:, :embed_dim]  # Ensure the shape matches [num_patches, embed_dim]\n",
        "\n",
        "    def call(self, x):\n",
        "        return x + self.pos_encoding\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2XenNMbgQqq6"
      },
      "outputs": [],
      "source": [
        "class TransformerEncoderBlock(Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, dropout_rate=0.1):\n",
        "        super(TransformerEncoderBlock, self).__init__()\n",
        "        self.att = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = tf.keras.Sequential([\n",
        "            Dense(ff_dim, activation='relu'),\n",
        "            Dense(embed_dim),\n",
        "        ])\n",
        "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = Dropout(dropout_rate)\n",
        "        self.dropout2 = Dropout(dropout_rate)\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        attn_output = self.att(inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0DZ-m49yQsO_"
      },
      "outputs": [],
      "source": [
        "def create_vit_model(input_shape, patch_size, embed_dim, num_heads, ff_dim, num_layers, num_classes):\n",
        "    inputs = tf.keras.Input(shape=input_shape)\n",
        "    patches = PatchEmbedding(patch_size, embed_dim)(inputs)\n",
        "    num_patches = (input_shape[0] // patch_size) * (input_shape[1] // patch_size)\n",
        "    positions = PositionalEncoding(num_patches, embed_dim)(patches)\n",
        "    x = positions\n",
        "\n",
        "    for _ in range(num_layers):\n",
        "        x = TransformerEncoderBlock(embed_dim, num_heads, ff_dim)(x)\n",
        "\n",
        "    x = LayerNormalization(epsilon=1e-6)(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(ff_dim, activation='relu')(x)\n",
        "    x = Dropout(0.1)(x)\n",
        "    outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    return tf.keras.Model(inputs=inputs, outputs=outputs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7cf-p9EgQt3_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5jNEcKc_RCTB"
      },
      "outputs": [],
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train = x_train.astype(\"int32\") / 255.0\n",
        "x_test = x_test.astype(\"int32\") / 255.0\n",
        "\n",
        "# One-hot encode labels\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2Jo62nFS8xq"
      },
      "outputs": [],
      "source": [
        "vit_model = create_vit_model(\n",
        "    input_shape=(32, 32, 3),\n",
        "    patch_size=4,\n",
        "    embed_dim=64,\n",
        "    num_heads=4,\n",
        "    ff_dim=128,\n",
        "    num_layers=8,\n",
        "    num_classes=10\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4AjInoEsS9eK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acda243a-bc3c-4bf6-cacf-f239d3755ba8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 43ms/step - accuracy: 0.1885 - loss: 2.1956 - val_accuracy: 0.3933 - val_loss: 1.7012\n",
            "Epoch 2/100\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 26ms/step - accuracy: 0.3994 - loss: 1.6703 - val_accuracy: 0.4722 - val_loss: 1.4432\n",
            "Epoch 3/100\n",
            "\u001b[1m289/625\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - accuracy: 0.4653 - loss: 1.4883"
          ]
        }
      ],
      "source": [
        "vit_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=3e-4),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# Train Model\n",
        "history = vit_model.fit(x_train, y_train, batch_size=64, epochs=100, validation_split=0.2,verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q6kVUI16qZgU"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}